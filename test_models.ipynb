{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e98a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "#from index.load_index import load_index\n",
    "from models import BM25RetrievalModel, TFIDFRetrievalModel, DenseRetrievalModel, HybridRetrievalModel\n",
    "from evaluation import evaluate, tune_hybrid_alpha, plot_alpha_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c70707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Indexed Documents\n",
    "#sys.path.append(\".\")   # Adjust depending on your layout\n",
    "index_dir = \"tuebingen_index\"  # Update if stored elsewhere\n",
    "documents = load_index(index_dir)\n",
    "\n",
    "texts = [doc[\"text\"] for doc in documents]\n",
    "urls = [doc[\"url\"] for doc in documents]\n",
    "\n",
    "print(f\"Loaded {len(texts)} documents from index.\")\n",
    "# Load Retrieval Models\n",
    "bm25_model = BM25RetrievalModel(texts, urls)\n",
    "tfidf_model = TFIDFRetrievalModel(texts, urls)\n",
    "dense_model = DenseRetrievalModel(texts, urls)\n",
    "hybrid_model = HybridRetrievalModel(bm25_model, dense_model, alpha=0.5)\n",
    "\n",
    "queries = [\n",
    "    \"tübingen attractions\",\n",
    "    \"food and drinks\",\n",
    "    \"university of tübingen history\",\n",
    "    \"student life\",\n",
    "    \"museums in tübingen\"\n",
    "]\n",
    "# Evaluate Models on Queries\n",
    "def display_results(model, model_name, query, top_n=5):\n",
    "    print(f\"\\n{model_name} Results for: \\\"{query}\\\"\")\n",
    "    results = model.retrieve(query, top_k=top_n)\n",
    "    for i, res in enumerate(results):\n",
    "        print(f\"{i+1}. {res['url']} (Score: {res['score']:.4f})\")\n",
    "        print(f\"   {res['snippet'][:200]}...\\n\")\n",
    "\n",
    "for query in queries:\n",
    "    display_results(bm25_model, \"BM25\", query)\n",
    "    display_results(tfidf_model, \"TF-IDF\", query)\n",
    "    display_results(dense_model, \"Dense Embedding\", query)\n",
    "    display_results(hybrid_model, \"Hybrid Model (BM25 + Dense)\", query)\n",
    "    \n",
    "# Compare Side-by-Side\n",
    "def get_result_df(model, query, top_n=5):\n",
    "    results = model.retrieve(query, top_k=top_n)\n",
    "    return pd.DataFrame([{\n",
    "        'Rank': i + 1,\n",
    "        'URL': res['url'],\n",
    "        'Score': res['score'],\n",
    "        'Snippet': res['snippet'][:150]\n",
    "    } for i, res in enumerate(results)])\n",
    "\n",
    "query_idx = 0  # Choose from 0 to len(queries)-1\n",
    "query = queries[query_idx]\n",
    "\n",
    "print(f\"\\n\\nSide-by-Side Result for Query: \\\"{query}\\\"\")\n",
    "bm25_df = get_result_df(bm25_model, query)\n",
    "tfidf_df = get_result_df(tfidf_model, query)\n",
    "dense_df = get_result_df(dense_model, query)\n",
    "hybrid_df = get_result_df(hybrid_model, query)\n",
    "\n",
    "print(\"\\nBM25 Top Results:\")\n",
    "display(bm25_df)\n",
    "\n",
    "print(\"\\nTF-IDF Top Results:\")\n",
    "display(tfidf_df)\n",
    "\n",
    "print(\"\\nDense Embedding Top Results:\")\n",
    "display(dense_df)\n",
    "\n",
    "print(\"\\nHybrid Model Top Results:\")\n",
    "display(hybrid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acb8914",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BM25 Evaluation:\")\n",
    "print(evaluate(bm25_model, 'queries.txt', 'qrels.txt', k=10))\n",
    "\n",
    "print(\"Dense Evaluation:\")\n",
    "print(evaluate(dense_model, 'queries.txt', 'qrels.txt', k=10))\n",
    "\n",
    "print(\"Hybrid Evaluation:\")\n",
    "print(evaluate(hybrid_model, 'queries.txt', 'qrels.txt', k=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c21a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha, scores = tune_hybrid_alpha(\n",
    "    bm25_model,\n",
    "    dense_model,\n",
    "    queries_path='queries.txt',\n",
    "    qrels_path='qrels.txt',\n",
    "    k=10\n",
    ")\n",
    "plot_alpha_scores(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSE-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
